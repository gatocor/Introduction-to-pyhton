{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we aim to apply the different notions we are learning during the course.\n",
    "\n",
    "We will perform a basic data analysis of a very simple set of experiments in a guided way. The idea is that you write your own code to solve the differents steps. If you get stuck in a step, you will find tips by checking the code of the markdown cell. If you find it really difficult to progress to the next step or you can compare your code, you can find the solution in the solved notebook. \n",
    "\n",
    "# Final Project: Experiments and objectives\n",
    "\n",
    "We have performed a set of cell cultures in which cells with a GFP reporter are treated under diverse conditions.\n",
    "\n",
    "We have the following experiment:\n",
    "\n",
    " - Culture images of Bright Field and GFP channels for the control and the different conditions:\n",
    "    - Control sample\n",
    "    - 7 Condition samples\n",
    "\n",
    "We would like to check:\n",
    " - How the conditions change:\n",
    "    - Number of cells in the culture\n",
    "    - The size of the cells\n",
    "    - The proportion of cells\n",
    "    - The GFP expression\n",
    "\n",
    "## Setting up\n",
    "\n",
    "The data that we will analyze in this project is fake. To generate it you have to run the code in `make_data.py` running it from the `8_Project` folder.\n",
    "\n",
    "```\n",
    ".../8_Project> python make_data.py\n",
    "```\n",
    "\n",
    "If you run it correctly, the folder `8_Project/data` will populate with some data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload packages\n",
    "\n",
    "It is a good practice to put all the packages that you are going to import at the beginning of the document so you always know the packages that you have access to. In the following cell, put the packages that you will be requiring for the analysis as you need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add package importation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First project: Analysis of Image Data\n",
    "\n",
    "The first thing we would like to analyze is the data coming from the imaging experiments. \n",
    "\n",
    "In the following, we will go over the steps in a guided mode to apply the different concepts that we learned during the course.\n",
    "\n",
    "## Have a first look at the data\n",
    "\n",
    "The first thing to do would be to have a look at the data that we are dealing with. \n",
    "\n",
    " 1. Import the packages that you may need for this purpose\n",
    "<!-- You will need matplotlib.pyplot and skimage.io -->\n",
    " 2. Load the Control Samples\n",
    "<!-- May need to use io.imread -->\n",
    " 3. Plot them in a figure with two axes and add the comments that you may find relevant to the figure\n",
    "<!-- May need to use the following functions:\n",
    " - plt.subplots or plt.subplots_mosaic\n",
    " - ax.imshow\n",
    " - ax.set_title -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is composed of blobs of different sizes and the GFP expression of the cells fluctuate between cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find particles in the images\n",
    "\n",
    "Our particles are quite spherical. These particles are also called blobs. \n",
    "\n",
    " 1. Look in `scikit-image` for a function to detect blobs and read the documentation.\n",
    "<!-- https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_blob.html?highlight=blob%20detection -->\n",
    "\n",
    "We are going to use this function to detect our blobs. \n",
    "\n",
    " 2. Add to import the required packages that you may need.\n",
    " 3. Use the found function to detect the blobs in the bright field image and check the returning object. That means each row and each column?\n",
    "<!-- Use `feature.blob_log` -->\n",
    " 4. Visualize the results by plotting a red point over each found blob. (Pay attention that `imshow` plots X, Y axis reversed respect to `scatter``).\n",
    "Use `sns.scatter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find blobs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot blobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5. The detection was good but there are some mistakes. This is because the blob detection algorithm requires to tune appropriately the parameters `min_sigma` and `max_sigma`. Try 5 and 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find blobs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot blobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a lot better, there are still some blobs not detected and some mistakes but the vast majority of blobs are correctly detected. For our purposes, this is more than okay. \n",
    "\n",
    "This is the good thing about python being an interpreted language and having a tool like jupyter lab: We can immediately see the partial results and adapt our analysis as we produce it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the intensity of each particle\n",
    "\n",
    "Now that we have the image, we want to measure the intensity of each particle.\n",
    "\n",
    " 1. Get the intensity of each particle using the position of the centers extracted. Notice that the blobs positions are given in float format. For being positions of an array they have to be integers.\n",
    "<!-- You can use a for loop going over each blob result or you can find all the centers all at once giving all the positions at the same time. Notice that the  -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get intensity of each blob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get intensity of each blob (SHORT ALTERNATIVE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put all the blob information in a DataFrame\n",
    "\n",
    "Now we have an array with the position and radius of the blobs and other with the intensity of the blobs. It may be convenient to group everything together in a single object. A DataFrame seems a good object for storing this data as we have table-like information (blobs x properties) and each property is of a different format:\n",
    "\n",
    " - x and y are integers\n",
    " - radius is a float\n",
    " - GFP expression is a float\n",
    "\n",
    " 1. Make a DataFrame with all the information of the blobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a function Automatize the pipeline\n",
    "\n",
    "Now all the information that we need for our object is inside the DataFrame. We will have to get this information for each experimental condition. This means that we will have to repeat many times.\n",
    "\n",
    "It seems convenient to put the pipeline in the form of a function that takes the images and returns the DataFrame with the detected blobs and the DataFrame.\n",
    "\n",
    " 1. Make a function that takes the images and returns the DataFrame with the blobs and their information.\n",
    " 2. Check that the function returns the dataframe as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code of the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the analysis for all the samples\n",
    "\n",
    "Now, we can do the analysis for all the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the files and visualize them\n",
    "\n",
    "Now that we had a first look at the data and we managed to open it, let's automatize the loading process.\n",
    "\n",
    " 1. Load all the files in a container for bright fields and other for images with BFP\n",
    " 2. Plot all the files adding appropriate comments to the image\n",
    "<!-- You can use two dictionaries and use a for loop to automatize the process. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the analysis for all the samples and add them to a joint DataFrame\n",
    "\n",
    "Now analyze all the samples and put all the DataFrames together. For that, you will have to add a column to the DataFrame that indicates the sample each blob came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a joint dataframe with all the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the data\n",
    "\n",
    "Finally, we are ready to analyze the dataset. We want to check:\n",
    "\n",
    " - Change in the distribution of blob sizes by condition\n",
    " - Change in the expression of GFP by condition\n",
    "\n",
    "### Visualize by conditions\n",
    "\n",
    "We can make many plots to check the different conditions. However, it is possible to show all the information with a single plot exploiting the capabilities of seaborn.\n",
    "\n",
    " - Change of Distribution -> histogram or violinplot\n",
    "\n",
    "Variables\n",
    " - Condition (Category) -> x or hue\n",
    " - GFP expression (Continuum) -> y\n",
    " - Sizes (we have only two sizes of blobs, so it can be an Int or a Category) -> hue or x\n",
    "\n",
    " 1. Make a plot that contains all the information in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data we can see the following clear things:\n",
    "\n",
    " - Condition 2 has fewer cells of smaller size.\n",
    " - Condition 5 has more small cells expressing high values of GFP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make statistical analysis\n",
    "\n",
    "Let's Make the above statements more strict making a statistical test over the different conditions.\n",
    "\n",
    "For that, we would use a two-sample Kolgomorov Test to compare the distributions between the control and the different Conditions.\n",
    "\n",
    "Do:\n",
    "\n",
    " 1. Find a function that implements the Kolmorov test between two samples\n",
    "<!-- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html#scipy.stats.ks_2samp -->\n",
    " 2. Perform the test comparing each condition for the radius of the particles.\n",
    "<!-- You may use a loop for and slicing of the pandas DataFrame to extract the information you want from the object. -->\n",
    " 3. Perform the test comparing each condition with the GFP of the particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical analysis radius\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical analysis GFP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
